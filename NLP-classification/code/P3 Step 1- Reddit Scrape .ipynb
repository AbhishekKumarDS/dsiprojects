{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Webscraping, NLP and classification modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: \n",
    "\n",
    "I am a marketing data analyst looking to optimize advertising efficiency. My target audience for this project is people who work in tech support, and my goal is to effectively target this audience using the correct keywords relevant to them.\n",
    "\n",
    "To this end, I have decided to explore Reddit in order to classify posts, based on natural language processing. For this project, I will be focusing on primarily text-based subreddits to enable more accurate text analysis. To increase the complexity, I will aim to classify posts from similar subreddits to tease out the nuances that make them different.\n",
    "\n",
    "Thus, the subreddits I have chosen are  \n",
    "1) https://www.reddit.com/r/talesfromtechsupport/  \n",
    "2) https://www.reddit.com/r/talesfromcallcenters/\n",
    "\n",
    "Combined, the 2 subreddits have a total of 800,000 members. Both have a similar purpose, ie - rantings by support departments. Therefore, it will be interesting to see what makes them different, and if machine learning models can accurately classify posts to one or the other. \n",
    "\n",
    "For the sake of this project, I will be focusing on accurately classifying posts that belong to the tech support group.\n",
    "\n",
    "Therefore from a data science perspective the optimization parameter for my model should be accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement: \n",
    "\n",
    "\n",
    "### What are the indicative words that help to effectively target advertising to a niche user group (tech support staff)? \n",
    "\n",
    "## Data Science Challenge: \n",
    "\n",
    "### How can I accurately identify posts that belong to 2 subreddits that are very similar in purpose but show differences of nuance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of technical analysis: \n",
    "\n",
    "1) Data Scraping using Reddit API   \n",
    "2) Exploratory Data Analysis  \n",
    "3) Natural Language Processing and Classification Modelling (Logistic Regression and Naive Bayes)  \n",
    "4) Advanced Modelling with CARTs (Random Forest, Extra Trees, Support Vector Machine, ADA Boost, Gradient Boost) and Optimization  \n",
    "5) Fresh Reddit scrape for 'true' unseen data  \n",
    "6) Final Modelling with optimized parameters  \n",
    "\n",
    "#### In addition to the GA project requirement, I have also looked into a personal area of interest - \n",
    "\n",
    "7) Sentiment Analysis and Topic Modelling Visualization (Latent Dirichlet Allocation)   \n",
    "\n",
    "\n",
    "\n",
    "#### For ease of viewing, I have separated each section into a separate jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import ast # to convert string data to indexable list of dictionaries\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create header parameter for API\n",
    "headers_dict = {'User-agent':'hello-reddit-i-am-totally-not-a-bot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "sub1_pages length:  1\n",
      "sub01_after:  t3_jpe44f\n",
      "0 200\n",
      "sub2_pages length:  1\n",
      "sub2_after:  t3_jl1a98\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_jpe44f\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_jl1a98\n",
      "1 200\n",
      "sub1_pages length:  2\n",
      "sub01_after:  t3_jcxa01\n",
      "1 200\n",
      "sub2_pages length:  2\n",
      "sub2_after:  t3_j5r758\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_jcxa01\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_j5r758\n",
      "2 200\n",
      "sub1_pages length:  3\n",
      "sub01_after:  t3_j2r3sl\n",
      "2 200\n",
      "sub2_pages length:  3\n",
      "sub2_after:  t3_ipjvct\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_j2r3sl\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_ipjvct\n",
      "3 200\n",
      "sub1_pages length:  4\n",
      "sub01_after:  t3_it4gmh\n",
      "3 200\n",
      "sub2_pages length:  4\n",
      "sub2_after:  t3_icnreb\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_it4gmh\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_icnreb\n",
      "4 200\n",
      "sub1_pages length:  5\n",
      "sub01_after:  t3_iir2om\n",
      "4 200\n",
      "sub2_pages length:  5\n",
      "sub2_after:  t3_hz6thz\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_iir2om\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_hz6thz\n",
      "5 200\n",
      "sub1_pages length:  6\n",
      "sub01_after:  t3_i9iqq3\n",
      "5 200\n",
      "sub2_pages length:  6\n",
      "sub2_after:  t3_hmblev\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_i9iqq3\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_hmblev\n",
      "6 200\n",
      "sub1_pages length:  7\n",
      "sub01_after:  t3_hzff98\n",
      "6 200\n",
      "sub2_pages length:  7\n",
      "sub2_after:  t3_havo0c\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_hzff98\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_havo0c\n",
      "7 200\n",
      "sub1_pages length:  8\n",
      "sub01_after:  t3_honvh8\n",
      "7 200\n",
      "sub2_pages length:  8\n",
      "sub2_after:  t3_gt43j6\n",
      "https://reddit.com/r/talesfromcallcenters.json?limit=100&after=t3_honvh8\n",
      "https://reddit.com/r/talesfromtechsupport.json?limit=100&after=t3_gt43j6\n",
      "8 200\n",
      "sub1_pages length:  9\n",
      "sub01_after:  None\n",
      "8 200\n",
      "sub2_pages length:  9\n",
      "sub2_after:  t3_gf18k9\n",
      "After reference out of sync.\n"
     ]
    }
   ],
   "source": [
    "# instantiate API variables\n",
    "url = 'https://reddit.com/'\n",
    "sub1_url = url + 'r/talesfromcallcenters'           # setting sub1 \n",
    "sub2_url = url + 'r/talesfromtechsupport'        # setting sub2 \n",
    "\n",
    "limit_num = 100     # API 'limit' parameter\n",
    "\n",
    "sub1_after = None  # instantiate empty counters for API 'after' parameter\n",
    "sub2_after = None\n",
    "\n",
    "sub1_pages = []    # instantiate empty lists to save API results\n",
    "sub2_pages = []\n",
    "\n",
    "for i in range(20): # pull from API 20 times\n",
    "    \n",
    "    # add 'after' parameters if an id has been saved - starts as None\n",
    "    if sub1_after and sub2_after:\n",
    "        # create full API url for sub1\n",
    "        sub1_after_url = sub1_url + '.json?limit=' \\\n",
    "                            + str(limit_num) + '&after=' \\\n",
    "                            + sub1_after\n",
    "        print(sub1_after_url)\n",
    "        \n",
    "        # create full API url for sub2\n",
    "        sub2_after_url = sub2_url + '.json?limit=' \\\n",
    "                            + str(limit_num) + '&after=' \\\n",
    "                            + sub2_after\n",
    "        print(sub2_after_url)\n",
    "    \n",
    "    # if one after is logged and the other is not\n",
    "    elif bool(sub1_after) != bool(sub2_after):\n",
    "        print('After reference out of sync.')\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        # create first run url\n",
    "        sub1_after_url = sub1_url + '.json?limit=' + str(limit_num)\n",
    "        sub2_after_url = sub2_url + '.json?limit=' + str(limit_num)\n",
    "    \n",
    "    # pull json from sub1\n",
    "    sub1_res = requests.get(sub1_after_url, headers=headers_dict)\n",
    "    print(i, sub1_res.status_code)\n",
    "    \n",
    "    # if sub1 connection is established\n",
    "    if sub1_res.status_code == 200:\n",
    "        # add page to list\n",
    "        sub1_pages.append(sub1_res.json()['data'])\n",
    "        print('sub1_pages length: ', len(sub1_pages))\n",
    "        \n",
    "        # set 'after' parameter for next run\n",
    "        sub1_after = sub1_res.json()['data']['after']\n",
    "        print('sub01_after: ', sub1_after)\n",
    "        \n",
    "    else:        \n",
    "        print('Connection failed.\\n')\n",
    "    \n",
    "    # sleep one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # pull json from sub2\n",
    "    sub2_res = requests.get(sub2_after_url, headers=headers_dict)\n",
    "    print(i, sub2_res.status_code)\n",
    "    \n",
    "    # if sub2 connection is established\n",
    "    if sub2_res.status_code == 200:\n",
    "        # add page to list\n",
    "        sub2_pages.append(sub2_res.json()['data'])\n",
    "        print('sub2_pages length: ', len(sub2_pages))\n",
    "        \n",
    "        # set 'after' parameter for next run\n",
    "        sub2_after = sub2_res.json()['data']['after']\n",
    "        print('sub2_after: ', sub2_after)\n",
    "    else:\n",
    "        print('Connection failed.\\n')\n",
    "        \n",
    "    # sleep 2 seconds    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrames from posting lists\n",
    "sub1_df = pd.DataFrame(sub1_pages)\n",
    "sub2_df = pd.DataFrame(sub2_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save API data to files\n",
    "sub1_df.to_csv('../datasets/sub1_scrape_27nov.csv', index=False)\n",
    "sub2_df.to_csv('../datasets/sub2_scrape_27nov.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint after data scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_df = pd.read_csv('../datasets/sub1_scrape_27nov.csv')\n",
    "sub2_df = pd.read_csv('../datasets/sub2_scrape_27nov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_df['children'] = sub1_df.children.map(lambda x: ast.literal_eval(x))\n",
    "sub2_df['children'] = sub2_df.children.map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the scrape into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save post dictionaries in arrays\n",
    "\n",
    "sub1 = sub1_df['children']\n",
    "sub2 = sub2_df['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approved_at_utc': None,\n",
       " 'subreddit': 'talesfromcallcenters',\n",
       " 'selftext': 'I get that tempers are shorter these days, but I am having a hard time lately with people taking out their frustrations on me, because I happen to be convenient.\\n\\nI work in an inbound support call centre, and we try very hard not to release the call if possible.  But I spoke to a real “Special” person today.\\n\\nShe’s going to file a complaint because I pointed out that she violated our terms of use.\\n\\nI am so close to being done with all of this....  (the job, I mean)\\n\\n\\nThanks for the awards!\\nThanks, everyone, for your support.  Definitely feeling better.',\n",
       " 'author_fullname': 't2_3zqnh8ue',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': 'Just need to vent...',\n",
       " 'link_flair_richtext': [],\n",
       " 'subreddit_name_prefixed': 'r/talesfromcallcenters',\n",
       " 'hidden': False,\n",
       " 'pwls': 6,\n",
       " 'link_flair_css_class': 'short',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'top_awarded_type': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_k1kkbd',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'dark',\n",
       " 'upvote_ratio': 0.99,\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 230,\n",
       " 'total_awards_received': 3,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': 'S',\n",
       " 'can_mod_post': False,\n",
       " 'score': 230,\n",
       " 'approved_by': None,\n",
       " 'author_premium': False,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': 1606446042.0,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {'gid_1': 1},\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1606444088.0,\n",
       " 'link_flair_type': 'text',\n",
       " 'wls': 6,\n",
       " 'removed_by_category': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'domain': 'self.talesfromcallcenters',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get that tempers are shorter these days, but I am having a hard time lately with people taking out their frustrations on me, because I happen to be convenient.&lt;/p&gt;\\n\\n&lt;p&gt;I work in an inbound support call centre, and we try very hard not to release the call if possible.  But I spoke to a real “Special” person today.&lt;/p&gt;\\n\\n&lt;p&gt;She’s going to file a complaint because I pointed out that she violated our terms of use.&lt;/p&gt;\\n\\n&lt;p&gt;I am so close to being done with all of this....  (the job, I mean)&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for the awards!\\nThanks, everyone, for your support.  Definitely feeling better.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       " 'likes': None,\n",
       " 'suggested_sort': None,\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': False,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'all_awardings': [{'giver_coin_reward': None,\n",
       "   'subreddit_id': None,\n",
       "   'is_new': False,\n",
       "   'days_of_drip_extension': 0,\n",
       "   'coin_price': 300,\n",
       "   'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3',\n",
       "   'penny_donate': None,\n",
       "   'award_sub_type': 'GLOBAL',\n",
       "   'coin_reward': 0,\n",
       "   'icon_url': 'https://i.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png',\n",
       "   'days_of_premium': 0,\n",
       "   'tiers_by_required_awardings': None,\n",
       "   'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=16&amp;height=16&amp;auto=webp&amp;s=c1400eb6ea235d0c96c3aa6e271c71d7f339cbd4',\n",
       "     'width': 16,\n",
       "     'height': 16},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=32&amp;height=32&amp;auto=webp&amp;s=77ad345b2f9b062140e028764394594326771a17',\n",
       "     'width': 32,\n",
       "     'height': 32},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=48&amp;height=48&amp;auto=webp&amp;s=5b5211166e4b260311ad9f3ea31d3b815110769c',\n",
       "     'width': 48,\n",
       "     'height': 48},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=64&amp;height=64&amp;auto=webp&amp;s=bf3a2c642ad50547087d770c65c29777970d3af3',\n",
       "     'width': 64,\n",
       "     'height': 64},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=128&amp;height=128&amp;auto=webp&amp;s=eae06d6a70c62c78dc66cb14f2a84651cb822cc4',\n",
       "     'width': 128,\n",
       "     'height': 128}],\n",
       "   'icon_width': 2048,\n",
       "   'static_icon_width': 2048,\n",
       "   'start_date': None,\n",
       "   'is_enabled': True,\n",
       "   'awardings_required_to_grant_benefits': None,\n",
       "   'description': \"When an upvote just isn't enough, smash the Rocket Like.\",\n",
       "   'end_date': None,\n",
       "   'subreddit_coin_reward': 0,\n",
       "   'count': 2,\n",
       "   'static_icon_height': 2048,\n",
       "   'name': 'Rocket Like',\n",
       "   'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=16&amp;height=16&amp;auto=webp&amp;s=c1400eb6ea235d0c96c3aa6e271c71d7f339cbd4',\n",
       "     'width': 16,\n",
       "     'height': 16},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=32&amp;height=32&amp;auto=webp&amp;s=77ad345b2f9b062140e028764394594326771a17',\n",
       "     'width': 32,\n",
       "     'height': 32},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=48&amp;height=48&amp;auto=webp&amp;s=5b5211166e4b260311ad9f3ea31d3b815110769c',\n",
       "     'width': 48,\n",
       "     'height': 48},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=64&amp;height=64&amp;auto=webp&amp;s=bf3a2c642ad50547087d770c65c29777970d3af3',\n",
       "     'width': 64,\n",
       "     'height': 64},\n",
       "    {'url': 'https://preview.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png?width=128&amp;height=128&amp;auto=webp&amp;s=eae06d6a70c62c78dc66cb14f2a84651cb822cc4',\n",
       "     'width': 128,\n",
       "     'height': 128}],\n",
       "   'icon_format': None,\n",
       "   'icon_height': 2048,\n",
       "   'penny_price': None,\n",
       "   'award_type': 'global',\n",
       "   'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/94pn64yuas941_RocketLike.png'},\n",
       "  {'giver_coin_reward': None,\n",
       "   'subreddit_id': None,\n",
       "   'is_new': False,\n",
       "   'days_of_drip_extension': 0,\n",
       "   'coin_price': 100,\n",
       "   'id': 'gid_1',\n",
       "   'penny_donate': None,\n",
       "   'award_sub_type': 'GLOBAL',\n",
       "   'coin_reward': 0,\n",
       "   'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png',\n",
       "   'days_of_premium': 0,\n",
       "   'tiers_by_required_awardings': None,\n",
       "   'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png',\n",
       "     'width': 16,\n",
       "     'height': 16},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png',\n",
       "     'width': 32,\n",
       "     'height': 32},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png',\n",
       "     'width': 48,\n",
       "     'height': 48},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png',\n",
       "     'width': 64,\n",
       "     'height': 64},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png',\n",
       "     'width': 128,\n",
       "     'height': 128}],\n",
       "   'icon_width': 512,\n",
       "   'static_icon_width': 512,\n",
       "   'start_date': None,\n",
       "   'is_enabled': True,\n",
       "   'awardings_required_to_grant_benefits': None,\n",
       "   'description': \"Shows the Silver Award... and that's it.\",\n",
       "   'end_date': None,\n",
       "   'subreddit_coin_reward': 0,\n",
       "   'count': 1,\n",
       "   'static_icon_height': 512,\n",
       "   'name': 'Silver',\n",
       "   'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png',\n",
       "     'width': 16,\n",
       "     'height': 16},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png',\n",
       "     'width': 32,\n",
       "     'height': 32},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png',\n",
       "     'width': 48,\n",
       "     'height': 48},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png',\n",
       "     'width': 64,\n",
       "     'height': 64},\n",
       "    {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png',\n",
       "     'width': 128,\n",
       "     'height': 128}],\n",
       "   'icon_format': None,\n",
       "   'icon_height': 512,\n",
       "   'penny_price': None,\n",
       "   'award_type': 'global',\n",
       "   'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}],\n",
       " 'awarders': [],\n",
       " 'media_only': False,\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'treatment_tags': [],\n",
       " 'visited': False,\n",
       " 'removed_by': None,\n",
       " 'num_reports': None,\n",
       " 'distinguished': None,\n",
       " 'subreddit_id': 't5_2urem',\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '',\n",
       " 'id': 'k1kkbd',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': 'tanzanite20',\n",
       " 'discussion_type': None,\n",
       " 'num_comments': 23,\n",
       " 'send_replies': True,\n",
       " 'whitelist_status': 'all_ads',\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/talesfromcallcenters/comments/k1kkbd/just_need_to_vent/',\n",
       " 'parent_whitelist_status': 'all_ads',\n",
       " 'stickied': False,\n",
       " 'url': 'https://www.reddit.com/r/talesfromcallcenters/comments/k1kkbd/just_need_to_vent/',\n",
       " 'subreddit_subscribers': 208281,\n",
       " 'created_utc': 1606415288.0,\n",
       " 'num_crossposts': 0,\n",
       " 'media': None,\n",
       " 'is_video': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1[0][0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of titles\n",
    "sub1_titles = [sub1[i][j]['data']['title'] for i in range(len(sub1))\n",
    "            for j in range(len(sub1[i]))]\n",
    "\n",
    "\n",
    "sub2_titles = [sub2[i][j]['data']['title'] for i in range(len(sub2)) \n",
    "            for j in range(len(sub2[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of post using nested comprehensions\n",
    "sub1_posts = [sub1[i][j]['data']['selftext'] for i in range(len(sub1)) \n",
    "            for j in range(len(sub1[i]))]\n",
    "\n",
    "sub2_posts = [sub2[i][j]['data']['selftext'] for i in range(len(sub2)) \n",
    "            for j in range(len(sub2[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of upvotes using nested comprehensions\n",
    "sub1_ups = [sub1[i][j]['data']['ups'] for i in range(len(sub1)) \n",
    "            for j in range(len(sub1[i]))]\n",
    "\n",
    "sub2_ups = [sub2[i][j]['data']['ups'] for i in range(len(sub2)) \n",
    "            for j in range(len(sub2[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of upvotes using nested comprehensions\n",
    "sub1_gilded = [sub1[i][j]['data']['gilded'] for i in range(len(sub1)) \n",
    "            for j in range(len(sub1[i]))]\n",
    "\n",
    "sub2_gilded = [sub2[i][j]['data']['gilded'] for i in range(len(sub2)) \n",
    "            for j in range(len(sub2[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile lists into DataFrame\n",
    "sub1_df = pd.DataFrame([sub1_titles, sub1_posts, sub1_ups, sub1_gilded], index=['title','post','upvotes','gilded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose DF\n",
    "sub1_df = sub1_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>gilded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just need to vent...</td>\n",
       "      <td>I get that tempers are shorter these days, but...</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reverse call center post</td>\n",
       "      <td>On mobile so I hope I do this right.  \\n\\nI ha...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So you're willing to lose a customer for $3 d...</td>\n",
       "      <td>I work for a car rental company as a specialis...</td>\n",
       "      <td>763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Free Talk Friday - Nov 27</td>\n",
       "      <td>Welcome to Free Talk Friday! We are suspending...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accidentally Exposed a Family Fraud</td>\n",
       "      <td>I work for a small local ISP.  One of the thin...</td>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                               Just need to vent...   \n",
       "1                           Reverse call center post   \n",
       "2  \"So you're willing to lose a customer for $3 d...   \n",
       "3                          Free Talk Friday - Nov 27   \n",
       "4                Accidentally Exposed a Family Fraud   \n",
       "\n",
       "                                                post upvotes gilded  \n",
       "0  I get that tempers are shorter these days, but...     230      0  \n",
       "1  On mobile so I hope I do this right.  \\n\\nI ha...      39      0  \n",
       "2  I work for a car rental company as a specialis...     763      0  \n",
       "3  Welcome to Free Talk Friday! We are suspending...       0      0  \n",
       "4  I work for a small local ISP.  One of the thin...     958      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile lists into DataFrame\n",
    "sub2_df = pd.DataFrame([sub2_titles, sub2_posts, sub2_ups, sub2_gilded], index=['title','post','upvotes', 'gilded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose DF\n",
    "sub2_df = sub2_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the classifier: 'belongs_to_sub2' \n",
    "sub1_df['belongs_to_sub2'] = 0\n",
    "sub2_df['belongs_to_sub2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_df.to_csv('../datasets/sub1_df_27_nov.csv', index=False)\n",
    "sub2_df.to_csv('../datasets/sub2_df_27_nov.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the two subs\n",
    "df = pd.concat([sub1_df, sub2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.post.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_x_post'] = df['title'] + ' ' + df['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    901\n",
       "0    842\n",
       "Name: belongs_to_sub2, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.belongs_to_sub2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.516925\n",
       "0    0.483075\n",
       "Name: belongs_to_sub2, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check distribution of target variable\n",
    "df.belongs_to_sub2.value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>gilded</th>\n",
       "      <th>belongs_to_sub2</th>\n",
       "      <th>title_x_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just need to vent...</td>\n",
       "      <td>I get that tempers are shorter these days, but...</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just need to vent... I get that tempers are sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reverse call center post</td>\n",
       "      <td>On mobile so I hope I do this right.  \\n\\nI ha...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reverse call center post On mobile so I hope I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So you're willing to lose a customer for $3 d...</td>\n",
       "      <td>I work for a car rental company as a specialis...</td>\n",
       "      <td>763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"So you're willing to lose a customer for $3 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Free Talk Friday - Nov 27</td>\n",
       "      <td>Welcome to Free Talk Friday! We are suspending...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Free Talk Friday - Nov 27 Welcome to Free Talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accidentally Exposed a Family Fraud</td>\n",
       "      <td>I work for a small local ISP.  One of the thin...</td>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accidentally Exposed a Family Fraud I work for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                               Just need to vent...   \n",
       "1                           Reverse call center post   \n",
       "2  \"So you're willing to lose a customer for $3 d...   \n",
       "3                          Free Talk Friday - Nov 27   \n",
       "4                Accidentally Exposed a Family Fraud   \n",
       "\n",
       "                                                post upvotes gilded  \\\n",
       "0  I get that tempers are shorter these days, but...     230      0   \n",
       "1  On mobile so I hope I do this right.  \\n\\nI ha...      39      0   \n",
       "2  I work for a car rental company as a specialis...     763      0   \n",
       "3  Welcome to Free Talk Friday! We are suspending...       0      0   \n",
       "4  I work for a small local ISP.  One of the thin...     958      0   \n",
       "\n",
       "   belongs_to_sub2                                       title_x_post  \n",
       "0                0  Just need to vent... I get that tempers are sh...  \n",
       "1                0  Reverse call center post On mobile so I hope I...  \n",
       "2                0  \"So you're willing to lose a customer for $3 d...  \n",
       "3                0  Free Talk Friday - Nov 27 Welcome to Free Talk...  \n",
       "4                0  Accidentally Exposed a Family Fraud I work for...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>gilded</th>\n",
       "      <th>belongs_to_sub2</th>\n",
       "      <th>title_x_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>TFTS Top Tales - April 2020</td>\n",
       "      <td>Hi Everybody!\\n\\nHere's another month of Top T...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TFTS Top Tales - April 2020 Hi Everybody!\\n\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>I'm a corporate developer i know what im talki...</td>\n",
       "      <td>Hi, This is another story about working Tech S...</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm a corporate developer i know what im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>\"How did my contract details get on this websi...</td>\n",
       "      <td>So I am the youngest person at my work and som...</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"How did my contract details get on this websi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>No ma'am I cant turn that off...</td>\n",
       "      <td>I work as a printer technician, but specifical...</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No ma'am I cant turn that off... I work as a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Tycho Electric Anomaly</td>\n",
       "      <td>Thirty-nine years ago I did telephone tech sup...</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tycho Electric Anomaly Thirty-nine years ago I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "896                        TFTS Top Tales - April 2020   \n",
       "897  I'm a corporate developer i know what im talki...   \n",
       "898  \"How did my contract details get on this websi...   \n",
       "899                   No ma'am I cant turn that off...   \n",
       "900                             Tycho Electric Anomaly   \n",
       "\n",
       "                                                  post upvotes gilded  \\\n",
       "896  Hi Everybody!\\n\\nHere's another month of Top T...      37      0   \n",
       "897  Hi, This is another story about working Tech S...     187      0   \n",
       "898  So I am the youngest person at my work and som...     585      0   \n",
       "899  I work as a printer technician, but specifical...    1310      0   \n",
       "900  Thirty-nine years ago I did telephone tech sup...     401      0   \n",
       "\n",
       "     belongs_to_sub2                                       title_x_post  \n",
       "896                1  TFTS Top Tales - April 2020 Hi Everybody!\\n\\nH...  \n",
       "897                1  I'm a corporate developer i know what im talki...  \n",
       "898                1  \"How did my contract details get on this websi...  \n",
       "899                1  No ma'am I cant turn that off... I work as a p...  \n",
       "900                1  Tycho Electric Anomaly Thirty-nine years ago I...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/combined_27_nov_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
