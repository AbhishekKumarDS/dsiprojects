{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Webscraping, NLP and classification modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "\n",
    "1) Fresh train test split using new reddit pull  \n",
    "2) Running the model and answering the business question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# preprocessing imports\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# modeling imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('../datasets/cleaned_for_modelling_30_nov_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../datasets/fresh_test_data_cleaned_for_modelling_4dec_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>gilded</th>\n",
       "      <th>belongs_to_sub2</th>\n",
       "      <th>title_x_post</th>\n",
       "      <th>token</th>\n",
       "      <th>joined_text</th>\n",
       "      <th>highly_upvoted</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just need to vent...</td>\n",
       "      <td>I get that tempers are shorter these days, but...</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just need to vent... I get that tempers are sh...</td>\n",
       "      <td>['need', 'vent', 'get', 'tempers', 'shorter', ...</td>\n",
       "      <td>Just need to vent... I get that tempers are sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>579</td>\n",
       "      <td>need vent get tempers shorter days hard time l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reverse call center post</td>\n",
       "      <td>On mobile so I hope I do this right.  \\n\\nI ha...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reverse call center post On mobile so I hope I...</td>\n",
       "      <td>['reverse', 'call', 'center', 'post', 'mobile'...</td>\n",
       "      <td>Reverse call center post On mobile so I hope I...</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1017</td>\n",
       "      <td>reverse call center post mobile hope right cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"So you're willing to lose a customer for $3 d...</td>\n",
       "      <td>I work for a car rental company as a specialis...</td>\n",
       "      <td>763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"So you're willing to lose a customer for $3 d...</td>\n",
       "      <td>['willing', 'lose', 'customer', 'dollars', 'wo...</td>\n",
       "      <td>\"So you're willing to lose a customer for $3 d...</td>\n",
       "      <td>1</td>\n",
       "      <td>585</td>\n",
       "      <td>6757</td>\n",
       "      <td>willing lose customer dollars work car rental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Free Talk Friday - Nov 27</td>\n",
       "      <td>Welcome to Free Talk Friday! We are suspending...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Free Talk Friday - Nov 27 Welcome to Free Talk...</td>\n",
       "      <td>['free', 'talk', 'friday', 'nov', 'welcome', '...</td>\n",
       "      <td>Free Talk Friday - Nov 27 Welcome to Free Talk...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>368</td>\n",
       "      <td>free talk friday nov welcome free talk friday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accidentally Exposed a Family Fraud</td>\n",
       "      <td>I work for a small local ISP.  One of the thin...</td>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accidentally Exposed a Family Fraud I work for...</td>\n",
       "      <td>['accidentally', 'exposed', 'family', 'fraud',...</td>\n",
       "      <td>Accidentally Exposed a Family Fraud I work for...</td>\n",
       "      <td>1</td>\n",
       "      <td>366</td>\n",
       "      <td>3608</td>\n",
       "      <td>accidentally exposed family fraud work small l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                               Just need to vent...   \n",
       "1                           Reverse call center post   \n",
       "2  \"So you're willing to lose a customer for $3 d...   \n",
       "3                          Free Talk Friday - Nov 27   \n",
       "4                Accidentally Exposed a Family Fraud   \n",
       "\n",
       "                                                post  upvotes  gilded  \\\n",
       "0  I get that tempers are shorter these days, but...      230       0   \n",
       "1  On mobile so I hope I do this right.  \\n\\nI ha...       39       0   \n",
       "2  I work for a car rental company as a specialis...      763       0   \n",
       "3  Welcome to Free Talk Friday! We are suspending...        0       0   \n",
       "4  I work for a small local ISP.  One of the thin...      958       0   \n",
       "\n",
       "   belongs_to_sub2                                       title_x_post  \\\n",
       "0                0  Just need to vent... I get that tempers are sh...   \n",
       "1                0  Reverse call center post On mobile so I hope I...   \n",
       "2                0  \"So you're willing to lose a customer for $3 d...   \n",
       "3                0  Free Talk Friday - Nov 27 Welcome to Free Talk...   \n",
       "4                0  Accidentally Exposed a Family Fraud I work for...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['need', 'vent', 'get', 'tempers', 'shorter', ...   \n",
       "1  ['reverse', 'call', 'center', 'post', 'mobile'...   \n",
       "2  ['willing', 'lose', 'customer', 'dollars', 'wo...   \n",
       "3  ['free', 'talk', 'friday', 'nov', 'welcome', '...   \n",
       "4  ['accidentally', 'exposed', 'family', 'fraud',...   \n",
       "\n",
       "                                         joined_text  highly_upvoted  \\\n",
       "0  Just need to vent... I get that tempers are sh...               1   \n",
       "1  Reverse call center post On mobile so I hope I...               0   \n",
       "2  \"So you're willing to lose a customer for $3 d...               1   \n",
       "3  Free Talk Friday - Nov 27 Welcome to Free Talk...               0   \n",
       "4  Accidentally Exposed a Family Fraud I work for...               1   \n",
       "\n",
       "   word_count  char_count                                       cleaned_text  \n",
       "0          48         579  need vent get tempers shorter days hard time l...  \n",
       "1          84        1017  reverse call center post mobile hope right cal...  \n",
       "2         585        6757  willing lose customer dollars work car rental ...  \n",
       "3          38         368  free talk friday nov welcome free talk friday ...  \n",
       "4         366        3608  accidentally exposed family fraud work small l...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>post</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>gilded</th>\n",
       "      <th>belongs_to_sub2</th>\n",
       "      <th>title_x_post</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your Son is Seven and He's Getting WHAT?</td>\n",
       "      <td>So last night I had a very bizarre call from s...</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Your Son is Seven and He's Getting WHAT? So la...</td>\n",
       "      <td>son seven getting last night bizarre call some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No. You don’t get to speak to a manager.</td>\n",
       "      <td>So I had this call from a third party, which i...</td>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No. You don’t get to speak to a manager. So I ...</td>\n",
       "      <td>get speak manager call third party nothing new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am losing faith in humanity!</td>\n",
       "      <td>Why people give their SSN and DOB to random pe...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I am losing faith in humanity! Why people give...</td>\n",
       "      <td>losing faith humanity people give ssn dob rand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thanks for being Racist, Susan.</td>\n",
       "      <td>I am 50% white but I have an uncommon first na...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for being Racist, Susan. I am 50% white...</td>\n",
       "      <td>thanks racist susan white uncommon first name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let me vent to you about a dumb call I had today</td>\n",
       "      <td>So I am a team leader. We will call the custom...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Let me vent to you about a dumb call I had tod...</td>\n",
       "      <td>let vent dumb call today team leader call cust...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0          Your Son is Seven and He's Getting WHAT?   \n",
       "1          No. You don’t get to speak to a manager.   \n",
       "2                    I am losing faith in humanity!   \n",
       "3                   Thanks for being Racist, Susan.   \n",
       "4  Let me vent to you about a dumb call I had today   \n",
       "\n",
       "                                                post  upvotes  gilded  \\\n",
       "0  So last night I had a very bizarre call from s...      412       0   \n",
       "1  So I had this call from a third party, which i...      755       0   \n",
       "2  Why people give their SSN and DOB to random pe...       18       0   \n",
       "3  I am 50% white but I have an uncommon first na...        8       0   \n",
       "4  So I am a team leader. We will call the custom...        5       0   \n",
       "\n",
       "   belongs_to_sub2                                       title_x_post  \\\n",
       "0                0  Your Son is Seven and He's Getting WHAT? So la...   \n",
       "1                0  No. You don’t get to speak to a manager. So I ...   \n",
       "2                0  I am losing faith in humanity! Why people give...   \n",
       "3                0  Thanks for being Racist, Susan. I am 50% white...   \n",
       "4                0  Let me vent to you about a dumb call I had tod...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  son seven getting last night bizarre call some...  \n",
       "1  get speak manager call third party nothing new...  \n",
       "2  losing faith humanity people give ssn dob rand...  \n",
       "3  thanks racist susan white uncommon first name ...  \n",
       "4  let vent dumb call today team leader call cust...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_df['cleaned_text']\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_df['belongs_to_sub2']\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['cleaned_text']\n",
    "y_train = train_df['belongs_to_sub2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1743,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1743,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1743, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.516925\n",
       "0    0.483075\n",
       "Name: belongs_to_sub2, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to be tested\n",
    "\n",
    "\n",
    "Transformer: TF-IDF  \n",
    "Estimator: Naive Bayes (Hyperparameters - 'tf__max_features': 10000, 'tf__ngram_range': (1, 2))  \n",
    "Accuracy: 94%\n",
    "\n",
    "\n",
    "Transformer: CountVectorizer  \n",
    "Estimator: Naive Bayes (Hyperparameters - 'cvec__max_df': 0.9, 'cvec__max_features': 10000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2)}  \n",
    "Accuracy: 95%. \n",
    "\n",
    "\n",
    "Transformer: TF-IDF  \n",
    "Estimator: Random Forest (Hyperparameters - 'tf__max_features': 10000, 'tf__ngram_range': (1, 2))  \n",
    "Accuracy: 93%\n",
    "\n",
    "\n",
    "Transformer: TF-IDF\n",
    "Estimator: Extra Trees (Hyperparameters - 'tf__max_features': 10000, 'tf__ngram_range': (1, 2))  \n",
    "Accuracy: 93%.\n",
    "\n",
    "Transformer: TF-IDF\n",
    "Estimator: SVM (Hyperparameters - 'tf__max_features': 10000, 'tf__ngram_range': (1, 1))  \n",
    "Accuracy: 93%.\n",
    "\n",
    "Transformer: TF-IDF  \n",
    "Estimator: Log Reg (Hyperparameters - 'tf__max_features': 15000, 'tf__ngram_range': (1, 2))  \n",
    "Accuracy: 93%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: TF-IDF and NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.97\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('tf', TfidfVectorizer()),\n",
    "                ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "                'tf__max_features' : [10_000,],\n",
    "                'tf__ngram_range' : [(1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs1 = GridSearchCV(pipe, param_grid = params, cv = 5)\n",
    "\n",
    "gs1.fit(X_train, y_train)\n",
    "\n",
    "gs_train_accuracy = round(gs1.score(X_train, y_train),2)\n",
    "print(f'Train Accuracy: {gs_train_accuracy}')\n",
    "\n",
    "gs_test_accuracy = round(gs1.score(X_test, y_test),2)\n",
    "print(f'Test Accuracy: {gs_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 383\n",
      "False Positives: 17\n",
      "False Negatives: 11\n",
      "True Positives: 390\n",
      "\n",
      "Accuracy:  0.9650436953807741\n",
      "Sensitivity:  0.972568578553616\n",
      "Specificity:  0.9575\n",
      "Precision:  0.9582309582309583\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs1.predict(X_test)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: CountVectorizer and NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.97\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "params = {\n",
    "    'cvec__max_features' : [10_000],\n",
    "    'cvec__min_df' : [3],\n",
    "    'cvec__max_df': [0.9],\n",
    "    'cvec__ngram_range' : [(1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs2 = GridSearchCV(pipe, param_grid = params, cv = 5)\n",
    "\n",
    "gs2.fit(X_train, y_train)\n",
    "\n",
    "gs_train_accuracy = round(gs2.score(X_train, y_train),2)\n",
    "print(f'Train Accuracy: {gs_train_accuracy}')\n",
    "\n",
    "gs_test_accuracy = round(gs2.score(X_test, y_test),2)\n",
    "print(f'Test Accuracy: {gs_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 391\n",
      "False Positives: 9\n",
      "False Negatives: 13\n",
      "True Positives: 388\n",
      "\n",
      "Accuracy:  0.9725343320848939\n",
      "Sensitivity:  0.9675810473815462\n",
      "Specificity:  0.9775\n",
      "Precision:  0.9773299748110831\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs2.predict(X_test)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: TF-IDF and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('tf', TfidfVectorizer()),\n",
    "                ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "                'tf__max_features' : [10_000,],\n",
    "                'tf__ngram_range' : [(1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs3 = GridSearchCV(pipe, param_grid = params, cv = 5)\n",
    "\n",
    "gs3.fit(X_train, y_train)\n",
    "\n",
    "gs_train_accuracy = round(gs3.score(X_train, y_train),2)\n",
    "print(f'Train Accuracy: {gs_train_accuracy}')\n",
    "\n",
    "gs_test_accuracy = round(gs3.score(X_test, y_test),2)\n",
    "print(f'Test Accuracy: {gs_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 398\n",
      "False Positives: 2\n",
      "False Negatives: 0\n",
      "True Positives: 401\n",
      "\n",
      "Accuracy:  0.9975031210986267\n",
      "Sensitivity:  1.0\n",
      "Specificity:  0.995\n",
      "Precision:  0.9950372208436724\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs3.predict(X_test)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: TF-IDF and Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('tf', TfidfVectorizer()),\n",
    "                ('et', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "                'tf__max_features' : [10_000,],\n",
    "                'tf__ngram_range' : [(1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs4 = GridSearchCV(pipe, param_grid = params, cv = 5)\n",
    "\n",
    "gs4.fit(X_train, y_train)\n",
    "\n",
    "gs_train_accuracy = round(gs4.score(X_train, y_train),2)\n",
    "print(f'Train Accuracy: {gs_train_accuracy}')\n",
    "\n",
    "gs_test_accuracy = round(gs4.score(X_test, y_test),2)\n",
    "print(f'Test Accuracy: {gs_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 397\n",
      "False Positives: 3\n",
      "False Negatives: 1\n",
      "True Positives: 400\n",
      "\n",
      "Accuracy:  0.9950062421972534\n",
      "Sensitivity:  0.9975062344139651\n",
      "Specificity:  0.9925\n",
      "Precision:  0.9925558312655087\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs4.predict(X_test)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: TF-IDF and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('tf', TfidfVectorizer()),\n",
    "                ('svc', SVC())\n",
    "])\n",
    "\n",
    "params = {\n",
    "                'tf__max_features' : [10_000,],\n",
    "                'tf__ngram_range' : [(1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs5 = GridSearchCV(pipe, param_grid = params, cv = 5)\n",
    "\n",
    "gs5.fit(X_train, y_train)\n",
    "\n",
    "gs_train_accuracy = round(gs5.score(X_train, y_train),2)\n",
    "print(f'Train Accuracy: {gs_train_accuracy}')\n",
    "\n",
    "gs_test_accuracy = round(gs5.score(X_test, y_test),2)\n",
    "print(f'Test Accuracy: {gs_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 397\n",
      "False Positives: 3\n",
      "False Negatives: 1\n",
      "True Positives: 400\n",
      "\n",
      "Accuracy:  0.9950062421972534\n",
      "Sensitivity:  0.9975062344139651\n",
      "Specificity:  0.9925\n",
      "Precision:  0.9925558312655087\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs5.predict(X_test)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6: TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.98\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('tf', TfidfVectorizer()),\n",
    "                ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "                'tf__max_features' : [15_000,],\n",
    "                'tf__ngram_range' : [(1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs5 = GridSearchCV(pipe, param_grid = params, cv = 5)\n",
    "\n",
    "gs5.fit(X_train, y_train)\n",
    "\n",
    "gs_train_accuracy = round(gs5.score(X_train, y_train),2)\n",
    "print(f'Train Accuracy: {gs_train_accuracy}')\n",
    "\n",
    "gs_test_accuracy = round(gs5.score(X_test, y_test),2)\n",
    "print(f'Test Accuracy: {gs_test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 392\n",
      "False Positives: 8\n",
      "False Negatives: 8\n",
      "True Positives: 393\n",
      "\n",
      "Accuracy:  0.9800249687890137\n",
      "Sensitivity:  0.9800498753117207\n",
      "Specificity:  0.98\n",
      "Precision:  0.9800498753117207\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs5.predict(X_test)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder of Problem Statement: \n",
    "\n",
    "\n",
    "### What are the indicative words that help to effectively target advertising to a niche user group (tech support staff)? \n",
    "\n",
    "## Reminder of Data Science Challenge: \n",
    "\n",
    "### How can I accurately identify posts that belong to 2 subreddits that are very similar in purpose but show differences of nuance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With accuracy score of 99.7% on 'true' unseen data, Random Forest is theoretically the best model to answer the data science challenge. \n",
    "\n",
    "### However, Logistic Regression is a better way to answer the business problem, as the model is interpretable and I can get relevant keywords for better classification. With 98% accurary in logistic regression, I am confident to recommend this model for better advertising targeting.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
